{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import model.train_schedule\n",
    "import model.model_defination\n",
    "import torch\n",
    "from scipy.interpolate import griddata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'D:\\Programming\\CME_data\\CME\\Halo\\20130830_032405_lasc2rdf_aia193rdf.png'\n",
    "\n",
    "# img = Image.open(path).convert('L')\n",
    "# img = np.array(img, dtype=np.float32)\n",
    "# print('图片大小：', img.shape)\n",
    "# print(img)\n",
    "# img = np.expand_dims(img, 0)\n",
    "\n",
    "def loadSingleImg(path):\n",
    "    '''\n",
    "    载入单张图片\n",
    "    '''\n",
    "    img = Image.open(path).convert('L')\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = torch.from_numpy(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 预处理步骤\n",
    "首先，0.5级的LASCO C2数据文件会处理为1级数据。所有的1024*1024分辨率大小的图片会被下采样至512*512。然后，会经过噪声滤波以压制部分尖锐噪声。文中使用3*3正则化正方滤波器.该滤波器是基本的线性滤波器，计算邻近像素的平均值，然后再生成差分图。\n",
    "##### 图像分类\n",
    "所有的(1024,1024)差分图会被下采样(112,112)大小，作为神经网络的输入。经过卷积层1，输出为(20,108,108)，经过池化层1，输出为(20,54,54)，经过卷积层2，输出为(50,50,50)，经过池化层2，输出为(50,25,25).然后经过两全连接层，得到最终的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ho(h, f, padding, stride):\n",
    "    return (h - f + 2 * padding) / stride + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文中：\n",
      "108.0\n",
      "54.0\n",
      "50.0\n",
      "25.0\n",
      "我的工作：\n",
      "220.0\n",
      "110.0\n",
      "106.0\n",
      "53.0\n"
     ]
    }
   ],
   "source": [
    "# 原文中:input N*112*112\n",
    "print('原文中：')\n",
    "print(ho(112, 5, 0, 1)) # 卷积后N*108*108\n",
    "print(ho(108, 2, 0, 2)) # 池化后N*54*54\n",
    "print(ho(54, 5, 0, 1)) # 卷积后N*50*50\n",
    "print(ho(50, 2, 0, 2)) # 池化后N*25*25\n",
    "\n",
    "#我的工作中采用input为 N*224*224\n",
    "print('我的工作：')\n",
    "print(ho(224, 5, 0, 1))  # 卷积后N*220*220\n",
    "print(ho(220, 2, 0, 2))  # 池化后N*110*110\n",
    "print(ho(110, 5, 0, 1))  # 卷积后N*106*106\n",
    "print(ho(106, 2, 0, 2))  # 池化后N*53*53\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CME探测\n",
    "首先利用register_forward_hook函数得到卷积层输出的activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act: (1, 53, 53, 50)\n",
      "out: tensor([[-0.0251, -0.1121]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = model.model_defination.LeNet5()\n",
    "parameter_path = r'D:\\Programming\\codetest\\CMEclassfication\\train_info\\2022_03_28_22_06_07\\parameters.pkl'\n",
    "net.load_state_dict(torch.load(parameter_path))\n",
    "\n",
    "def getActivation(net: torch.nn.Module, x):\n",
    "    '''\n",
    "    获得最后一层卷积层的输出\n",
    "    输出结果的维度为N*h*w*d\n",
    "    '''\n",
    "    net.eval()\n",
    "    activation = []\n",
    "\n",
    "    def forward_hook(modeul, data_input, data_output):\n",
    "        activation.append(data_output.detach().permute(0, 2, 3, 1).numpy())\n",
    "\n",
    "    net.conv2.register_forward_hook(forward_hook)\n",
    "    out = net(x)\n",
    "    return activation[0]\n",
    "\n",
    "\n",
    "img = loadSingleImg(img_path)\n",
    "activat = getActivation(net, img)\n",
    "out = net(img)\n",
    "print('act:', activat.shape)\n",
    "print('out:', out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CME Co-localiaztion\n",
    "从卷积层的输出特征图中提取信息。利用DDT手段进行图像共定位(Co-locolization)。共定位就是在一系列的图像中找到相关物体的位置。对于一张H*W大小的图片，其activation(卷积层的输出)就是一个形状为h*w*d的三维张量。该张量可被认为有h*w个cell，每个cell包含一个d维的DD(deep desciptor)向量。  \n",
    "首先，有N张图片构成的序列，这N个图片包含着同一类别的目标。这N张图片生成N个activation，每一个activation都是k*w*d维的张量。计算这N个activation的平均张量，然后获得协方差矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanVector(x: np.ndarray):\n",
    "    '''\n",
    "    获得所有descriptor的平均向量\n",
    "    x为N*h*w*d维的np.array\n",
    "    '''\n",
    "    return np.mean(x, axis=(0, 1, 2))\n",
    "\n",
    "\n",
    "def cov(x: np.ndarray):\n",
    "    '''\n",
    "    获得协方差矩阵\n",
    "    x为N*h*w*d维的np.array\n",
    "    '''\n",
    "    k = x.shape[0] * x.shape[1] * x.shape[2]\n",
    "    xMeanVector = getMeanVector(x)\n",
    "    convMat = np.zeros(x.shape[3])\n",
    "    for n in range(x.shape[0]):\n",
    "        for i in range(x.shape[1]):\n",
    "            for j in range(x.shape[2]):\n",
    "                deviaVector = x[n][i][j] - xMeanVector\n",
    "                # 对x中取出的descripter向量进行升维\n",
    "                # 因为直接取出的descripter向量是一维的，直接相乘会出现问题，需转化为列向量\n",
    "                deviaVector = np.expand_dims(deviaVector, axis=1)\n",
    "                tempMat = np.matmul(deviaVector, deviaVector.T)\n",
    "                convMat = convMat + tempMat\n",
    "    return convMat / k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后求最大特征值所对应的特征向量以及指示矩阵。  \n",
    "原特征图的形状为(h,w,d)，可认为原特征图的每一个像素都构成了一个观测样本，d维的descripter向量就是该观测样本的值，再利用PCA的方法，求出该协方差矩阵的特征值和特征向量，并投影到最大特征值对应的特征向量方向上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 0 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n",
      "[[ 3.07185948  1.85890087  4.30295221 ...  4.27407304  3.24235773\n",
      "   2.98276511]\n",
      " [ 1.05905483  1.96643877  1.7301408  ... -0.01600396  3.38571335\n",
      "   4.42192161]\n",
      " [ 3.30727717  3.45816623  3.86915319 ...  3.43846296  2.84538142\n",
      "   1.34013851]\n",
      " ...\n",
      " [ 1.86057676  1.6644547   1.33671975 ...  3.4027091   3.11179547\n",
      "   3.89159221]\n",
      " [-0.33127379  1.25559069  2.22253688 ...  3.78662292  3.5761141\n",
      "   3.77138999]\n",
      " [ 4.07777616  1.73293969  3.5537941  ...  3.63792153  3.49725559\n",
      "   3.97261124]]\n"
     ]
    }
   ],
   "source": [
    "def getPrinCompVector(activation):\n",
    "    '''\n",
    "    获得主成分向量\n",
    "    x的形状为N*h*w*d\n",
    "    '''\n",
    "    covMatrix = cov(activation)\n",
    "    eigValue, eigVector = np.linalg.eig(covMatrix)\n",
    "    prinCompInd = np.argmax(eigValue)\n",
    "    prinCompVector = eigVector[:, prinCompInd]\n",
    "    # prinComp形状为(50,)，对其增加一维变为列向量\n",
    "    prinCompVector = np.expand_dims(prinCompVector, axis=1)\n",
    "    return prinCompVector\n",
    "\n",
    "\n",
    "def getIndicatorMatrix(x, ind, prinCompVector):\n",
    "    '''\n",
    "    获得索引为ind的图片的activation所对应的Indicator Matrix\n",
    "    x的维度为N*h*w*d,是N张图片的activation构成的数组\n",
    "    prinCompVector是最大特征值对应的主成分向量\n",
    "    '''\n",
    "    img = x[ind]\n",
    "    xMeanVector = getMeanVector(x)\n",
    "    indicatorMatrix = np.zeros((x.shape[1], x.shape[2]))\n",
    "    for i in range(x.shape[1]):\n",
    "        for j in range(x.shape[2]):\n",
    "            indicatorMatrix[i, j] = np.matmul(prinCompVector.T,\n",
    "                                              img[i, j] - xMeanVector)\n",
    "    return indicatorMatrix\n",
    "\n",
    "\n",
    "prinCompVector = getPrinCompVector(activat)\n",
    "indicatorMat = getIndicatorMatrix(activat, 0, prinCompVector)\n",
    "print(np.where(indicatorMat > 0, 1, 0))\n",
    "print(indicatorMat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指示矩阵的正值反映了d维descriptor的相关性大小。其值越大表明相关性越大。主成分向量是由N张图片获得的，因此正的相关性就反映了N张图片的共同特征。因此可以用0值作为阈值，大于0表示共同的物体，小于0表示背景或者不经常出现的物体。\n",
    "将指示矩阵利用最近邻插值，变为原图片的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reSize(x, targetSize=(224, 224)):\n",
    "    '''\n",
    "    将矩阵利用最近邻插值，变为224*224的大小\n",
    "    '''\n",
    "    pointXCoord = np.floor(np.linspace(0, targetSize[0] - 1, x.shape[0]))\n",
    "    pointYCoord = np.floor(np.linspace(0, targetSize[1] - 1, x.shape[1]))\n",
    "    pointCoord = np.array([(i, j) for i in pointXCoord for j in pointYCoord])\n",
    "    X = np.arange(0, targetSize[0])\n",
    "    Y = np.arange(0, targetSize[1])\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    reSizedX = griddata(pointCoord, x.flatten(), (X, Y), method='nearest')\n",
    "    # 此处返回的数组应为插值后的数组的转置，原因在于meshgrid生成的X,Y数组的顺序不同\n",
    "    reSizedX = reSizedX.T\n",
    "    return reSizedX\n",
    "\n",
    "\n",
    "reSizedIndicator = reSize(indicatorMat)\n",
    "reSizedIndicator.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后将大小改变后的指示矩阵二值化，大于0的值修改为1，小于0的值修改为0.然后利用flood-fill算法找到正值区域的最大连通分量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNextStartPoint(mask):\n",
    "    '''查找下一个未被标记的点的坐标，若有这样的点则返回一个这样的点的坐标，若无则返回None'''\n",
    "    ind = np.argwhere(mask == 0)\n",
    "    if ind.size > 0:\n",
    "        return tuple(ind[0])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def withIn(point, xBound, yBound):\n",
    "    '''\n",
    "    判断点point是否在界限内\n",
    "    \n",
    "    xBound和yBound均为二元组，分别为x和y坐标的上下界。\n",
    "    '''\n",
    "    if xBound[0] <= point[0] <= xBound[1] and yBound[0] <= point[1] <= yBound[\n",
    "            1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def getLargestComponet(reSizedIndicator):\n",
    "    '''\n",
    "    找到指示矩阵中的最大连通分量\n",
    "\n",
    "    mask为二维数组，mask中大于0的值表示连通分量，不同的大于0的值表示不同的连通分量。\n",
    "    componentIndex表示连通分量的个数\n",
    "    '''\n",
    "    binaryIndicatorMat = np.where(reSizedIndicator > 0, 1, 0)\n",
    "    # mask用于指示reSizedIndicator中同位置的点是否被标记\n",
    "    # 若某点为0，表示还未被搜索到，若为-1，表示此点不在搜索区域内，若为正数，则用以区分不同的连通分量\n",
    "    mask = np.zeros_like(reSizedIndicator)\n",
    "    # binaryIndicatorMat中为0的点不属于搜索范围，需要在fill中将相应的点标为-1\n",
    "    mask[binaryIndicatorMat == 0] = -1\n",
    "    # 指定flood-fill算法的起始点坐标\n",
    "    # TODO可以添加自行决定起始点的代码，而不是直接给定\n",
    "    # mask中起始点所对应的位置的值必须为0\n",
    "    filled = set()\n",
    "    #s = (0, 3)\n",
    "    s = getNextStartPoint(mask)\n",
    "    assert mask[s[0]][s[1]] == 0, '起始点不满足要求，请重新选择flood-fill算法起始点'\n",
    "    fill = set()\n",
    "    fill.add(s)\n",
    "    height, width = reSizedIndicator.shape[0] - 1, reSizedIndicator.shape[1] - 1\n",
    "    # componentIndex用于指示不同的连接分量，由1开始依次累加1\n",
    "    componentIndex = 1\n",
    "    while fill:\n",
    "        r, c = fill.pop()\n",
    "        # 去掉以下判断并在向fill中添加上下左右点时增加对界限的判断是因为\n",
    "        # 当(r,c)位于边界处，且此时fill为空时\n",
    "        # 由于continue的存在，会跳过寻找下一个起始点，直接结束循环，导致有连通分量被漏掉\n",
    "        # if c > width or r > height or r < 0 or c < 0:\n",
    "        #     continue\n",
    "        if mask[r][c] == 0:\n",
    "            #print(r,c,':',componentIndex)\n",
    "            mask[r][c] = componentIndex\n",
    "            filled.add((r, c))\n",
    "            leftUp = (r - 1, c - 1)\n",
    "            left = (r, c - 1)\n",
    "            leftDown = (r + 1, c - 1)\n",
    "            up = (r - 1, c)\n",
    "            down = (r + 1, c)\n",
    "            rightUp = (r - 1, c + 1)\n",
    "            right = (r, c + 1)\n",
    "            rightDown = (r + 1, c + 1)\n",
    "            if leftUp not in filled and withIn(leftUp, (0, height),(0, width)):\n",
    "                fill.add(leftUp)\n",
    "            if left not in filled and withIn(left, (0, height), (0, width)):\n",
    "                fill.add(left)\n",
    "            if leftDown not in filled and withIn(leftDown, (0, height),(0, width)):\n",
    "                fill.add(leftDown)\n",
    "            if up not in filled and withIn(up, (0, height), (0, width)):\n",
    "                fill.add(up)\n",
    "            if down not in filled and withIn(down, (0, height), (0, width)):\n",
    "                fill.add(down)\n",
    "            if rightUp not in filled and withIn(rightUp, (0, height),(0, width)):\n",
    "                fill.add(rightUp)\n",
    "            if right not in filled and withIn(right, (0, height), (0, width)):\n",
    "                fill.add(right)\n",
    "            if rightDown not in filled and withIn(rightDown, (0, height),(0, width)):\n",
    "                fill.add(rightDown)\n",
    "        # print(fill)\n",
    "        # 若fill中此时没有别的点了，标明上下左右邻近范围内的点都已被搜索完，则已经完成一个连通分量的搜索\n",
    "        # 需要进行下一个连通分量的搜索\n",
    "        if not fill:\n",
    "            nextPoint = getNextStartPoint(mask)\n",
    "            #print('next:',nextPoint)\n",
    "            if nextPoint:\n",
    "                fill.add(nextPoint)\n",
    "                componentIndex = componentIndex + 1\n",
    "    return mask, componentIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask, componetIndex = getLargestComponet(reSizedIndicator)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d77f6f2fe1d4ea854db94f6ad28dbb32cebc2f619ff9e2d22ef698e937c82f2"
  },
  "kernelspec": {
   "display_name": "PyCharm (CMEclassfication)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
