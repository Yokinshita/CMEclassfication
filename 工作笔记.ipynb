{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import model.train_schedule\n",
    "import model.model_defination\n",
    "import torch\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "from typing import Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# img = Image.open(path).convert('L')\n",
    "# img = np.array(img, dtype=np.float32)\n",
    "# print('图片大小：', img.shape)\n",
    "# print(img)\n",
    "# img = np.expand_dims(img, 0)\n",
    "\n",
    "def loadSingleImg(path:str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    载入单张图片，形状为NCHW\n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert('L')\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    # img = torch.from_numpy(img)\n",
    "    return img\n",
    "\n",
    "def loadImages(path_to_folder:str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    载入给定文件夹中的所有图片，形状为NCHW\n",
    "\n",
    "    返回np.ndarray\n",
    "    \"\"\"\n",
    "    pics = os.listdir(path_to_folder)\n",
    "    # 首先载入第一张图片\n",
    "    imgs = loadSingleImg(os.path.join(path_to_folder, pics[0]))\n",
    "    for i in range(1,len(pics)):\n",
    "        img = loadSingleImg(os.path.join(path_to_folder, pics[i]))\n",
    "        imgs = np.concatenate((imgs,img),axis=0)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 预处理步骤\n",
    "首先，0.5级的LASCO C2数据文件会处理为1级数据。所有的(1024,1024)分辨率大小的图片会被下采样至(512,512)。然后，会经过噪声滤波以压制部分尖锐噪声。文中使用3*3正则化正方滤波器.该滤波器是基本的线性滤波器，计算邻近像素的平均值，然后再生成差分图。\n",
    "##### 图像分类\n",
    "所有的(1024,1024)差分图会被下采样(112,112)大小，作为神经网络的输入。经过卷积层1，输出为(20,108,108)，经过池化层1，输出为(20,54,54)，经过卷积层2，输出为(50,50,50)，经过池化层2，输出为(50,25,25).然后经过两全连接层，得到最终的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ho(h, f, padding, stride):\n",
    "    return (h - f + 2 * padding) / stride + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 原文中:input N*112*112\n",
    "print('原文中：')\n",
    "print(ho(112, 5, 0, 1)) # 卷积后N*108*108\n",
    "print(ho(108, 2, 0, 2)) # 池化后N*54*54\n",
    "print(ho(54, 5, 0, 1)) # 卷积后N*50*50\n",
    "print(ho(50, 2, 0, 2)) # 池化后N*25*25\n",
    "\n",
    "#我的工作中采用input为 N*224*224\n",
    "print('我的工作：')\n",
    "print(ho(224, 5, 0, 1))  # 卷积后N*220*220\n",
    "print(ho(220, 2, 0, 2))  # 池化后N*110*110\n",
    "print(ho(110, 5, 0, 1))  # 卷积后N*106*106\n",
    "print(ho(106, 2, 0, 2))  # 池化后N*53*53\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### CME探测\n",
    "首先利用register_forward_hook函数得到卷积层输出的activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# net = model.model_defination.LeNet5()\n",
    "# img_path = r'D:\\Programming\\CME_data\\CME\\Halo\\20130830_032405_lasc2rdf_aia193rdf.png'\n",
    "# parameter_path = r'D:\\Programming\\codetest\\CMEclassfication\\log\\2022_04_13_20_00_25\\parameters.pkl'\n",
    "# map_location = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# net.load_state_dict(torch.load(parameter_path,map_location=map_location))\n",
    "\n",
    "def getActivation(net: torch.nn.Module, x:Union[torch.Tensor,np.ndarray]) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    获得最后一层卷积层的输出\n",
    "    \n",
    "    输出结果的维度为N*h*w*d\n",
    "    \"\"\"\n",
    "    if isinstance(x,np.ndarray):\n",
    "        x = torch.from_numpy(x)\n",
    "    net.eval()\n",
    "    activation = []\n",
    "\n",
    "    def forward_hook(modeul, data_input, data_output):\n",
    "        activation.append(data_output.detach().permute(0, 2, 3, 1).numpy())\n",
    "\n",
    "    net.conv2.register_forward_hook(forward_hook)\n",
    "    out = net(x)\n",
    "    return activation[0]\n",
    "\n",
    "\n",
    "# img = loadSingleImg(img_path)\n",
    "# activat = getActivation(net, img)\n",
    "# out = net(torch.from_numpy(img))\n",
    "# print('act:', activat.shape)\n",
    "# print('out:', torch.argmax(out, dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### CME Co-localiaztion\n",
    "从卷积层的输出特征图中提取信息。利用DDT手段进行图像共定位(Co-locolization)。共定位就是在一系列的图像中找到相关物体的位置。对于一张H*W大小的图片，其activation(卷积层的输出)就是一个形状为h*w*d的三维张量。该张量可被认为有h*w个cell，每个cell包含一个d维的DD(deep desciptor)向量。  \n",
    "首先，有N张图片构成的序列，这N个图片包含着同一类别的目标。这N张图片生成N个activation，每一个activation都是k*w*d维的张量。计算这N个activation的平均张量，然后获得协方差矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getMeanVector(x: np.ndarray):\n",
    "    \"\"\"\n",
    "    获得所有descriptor的平均向量\n",
    "    \n",
    "    x为N*h*w*d维的np.array\n",
    "    \"\"\"\n",
    "    return np.mean(x, axis=(0, 1, 2))\n",
    "\n",
    "\n",
    "def cov(x: np.ndarray):\n",
    "    \"\"\"\n",
    "    获得协方差矩阵\n",
    "    \n",
    "    x为N*h*w*d维的np.ndarray\n",
    "    \"\"\"\n",
    "    k = x.shape[0] * x.shape[1] * x.shape[2]\n",
    "    xMeanVector = getMeanVector(x)\n",
    "    convMat = np.zeros(x.shape[3])\n",
    "    for n in range(x.shape[0]):\n",
    "        for i in range(x.shape[1]):\n",
    "            for j in range(x.shape[2]):\n",
    "                deviaVector = x[n][i][j] - xMeanVector\n",
    "                # 对x中取出的descripter向量进行升维\n",
    "                # 因为直接取出的descripter向量是一维的，直接相乘会出现问题，需转化为列向量\n",
    "                deviaVector = np.expand_dims(deviaVector, axis=1)\n",
    "                tempMat = np.matmul(deviaVector, deviaVector.T)\n",
    "                convMat = convMat + tempMat\n",
    "    return convMat / k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "求最大特征值所对应的特征向量以及指示矩阵。  \n",
    "原特征图的形状为(h,w,d)，可认为原特征图的每一个像素都构成了一个观测样本，d维的descripter向量就是该观测样本的值，再利用PCA的方法，求出该协方差矩阵的特征值和特征向量，并投影到最大特征值对应的特征向量方向上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getPrinCompVector(activation: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    获得主成分向量\n",
    "    \n",
    "    activation的形状为N*h*w*d，是卷积层输出的特征图\n",
    "    \"\"\"\n",
    "    covMatrix = cov(activation)\n",
    "    eigValue, eigVector = np.linalg.eig(covMatrix)\n",
    "    prinCompInd = np.argmax(eigValue)\n",
    "    prinCompVector = eigVector[:, prinCompInd]\n",
    "    # prinComp形状为(50,)，对其增加一维变为列向量\n",
    "    prinCompVector = np.expand_dims(prinCompVector, axis=1)\n",
    "    return prinCompVector\n",
    "\n",
    "\n",
    "def getIndicatorMatrix(activation: np.ndarray, ind: int,\n",
    "                       prinCompVector: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"获得索引为ind的图片的activation所对应的Indicator Matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    activation : np.ndarray\n",
    "        维度为N*h*w*d,是N张图片的激活层构成的数组\n",
    "    ind : int\n",
    "        表示需求出指示矩阵的图片对应的索引\n",
    "    prinCompVector : np.ndarray\n",
    "        最大特征值对应的主成分向量\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray \n",
    "        指示矩阵\n",
    "    \"\"\"\n",
    "    img = activation[ind]\n",
    "    xMeanVector = getMeanVector(activation)\n",
    "    indicatorMatrix = np.zeros((activation.shape[1], activation.shape[2]))\n",
    "    for i in range(activation.shape[1]):\n",
    "        for j in range(activation.shape[2]):\n",
    "            indicatorMatrix[i, j] = np.matmul(prinCompVector.T,\n",
    "                                              img[i, j] - xMeanVector)\n",
    "    return indicatorMatrix\n",
    "\n",
    "\n",
    "# prinCompVector = getPrinCompVector(activat)\n",
    "# indicatorMat = getIndicatorMatrix(activat,0, prinCompVector)\n",
    "# print(np.where(indicatorMat > 0, 1, 0))\n",
    "# print(indicatorMat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "指示矩阵的正值反映了d维descriptor的相关性大小。其值越大表明相关性越大。主成分向量是由N张图片获得的，因此正的相关性就反映了N张图片的共同特征。因此可以用0值作为阈值，大于0表示共同的物体，小于0表示背景或者不经常出现的物体。\n",
    "将指示矩阵利用最近邻插值，变为原图片的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reSize(x: np.ndarray, targetSize=(512, 512)) -> np.ndarray:\n",
    "    \"\"\"利用最近邻插值，更改矩阵大小\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        需要变换的矩阵\n",
    "    targetSize : tuple, optional\n",
    "        目标大小, by default (512, 512)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        修改大小后的矩阵\n",
    "    \"\"\"\n",
    "    pointXCoord = np.floor(np.linspace(0, targetSize[0] - 1, x.shape[0]))\n",
    "    pointYCoord = np.floor(np.linspace(0, targetSize[1] - 1, x.shape[1]))\n",
    "    pointCoord = np.array([(i, j) for i in pointXCoord for j in pointYCoord])\n",
    "    X = np.arange(0, targetSize[0])\n",
    "    Y = np.arange(0, targetSize[1])\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    reSizedX = griddata(pointCoord, x.flatten(), (X, Y), method='nearest')\n",
    "    # 此处返回的数组应为插值后的数组的转置，原因在于meshgrid生成的X,Y数组的顺序不同\n",
    "    reSizedX = reSizedX.T\n",
    "    return reSizedX\n",
    "\n",
    "\n",
    "# reSizedIndicator = reSize(indicatorMat)\n",
    "# reSizedIndicator.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "将大小改变后的指示矩阵二值化，大于0的值修改为1，小于0的值修改为0.然后利用flood-fill算法找到正值区域的最大连通分量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getNextStartPoint(mask):\n",
    "    '''查找下一个未被标记的点的坐标，若有这样的点则返回一个这样的点的坐标，若无则返回None'''\n",
    "    ind = np.argwhere(mask == 0)\n",
    "    if ind.size > 0:\n",
    "        return tuple(ind[0])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def isInside(point:tuple, xBound:tuple, yBound:tuple) -> bool:\n",
    "    '''\n",
    "    判断点point是否在界限内\n",
    "    \n",
    "    xBound和yBound均为二元组，分别为x和y坐标的上下界。\n",
    "    '''\n",
    "    if xBound[0] <= point[0] <= xBound[1] and yBound[0] <= point[1] <= yBound[\n",
    "            1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def getConnectedComponet(reSizedIndicator:np.ndarray) -> tuple:\n",
    "    \"\"\"找到指示矩阵中的最大连通分量\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reSizedIndicator : np.ndarray\n",
    "        指示矩阵\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask : np.ndarray\n",
    "        连通分量的遮罩,为h*w二维数组,mask中大于0的值表示连通分量,不同的大于0的值表示不同的连通分量。\n",
    "    componentIndex : int\n",
    "        表示连通分量的个数\n",
    "    \"\"\"\n",
    "    binaryIndicatorMat = np.where(reSizedIndicator > 0, 1, 0)\n",
    "    # mask用于指示reSizedIndicator中同位置的点是否被标记\n",
    "    # 若某点为0，表示还未被搜索到，若为-1，表示此点不在搜索区域内，若为正数，则用以区分不同的连通分量\n",
    "    mask = np.zeros_like(reSizedIndicator)\n",
    "    # binaryIndicatorMat中为0的点不属于搜索范围，需要在fill中将相应的点标为-1\n",
    "    mask[binaryIndicatorMat == 0] = -1\n",
    "    # 指定flood-fill算法的起始点坐标\n",
    "    # mask中起始点所对应的位置的值必须为0\n",
    "    filled = set()\n",
    "    #s = (0, 3)\n",
    "    s = getNextStartPoint(mask)\n",
    "    assert mask[s[0]][s[1]] == 0, '起始点不满足要求，请重新选择flood-fill算法起始点'\n",
    "    fill = set()\n",
    "    fill.add(s)\n",
    "    height, width = reSizedIndicator.shape[0] - 1, reSizedIndicator.shape[1] - 1\n",
    "    # componentIndex用于指示不同的连接分量，由1开始依次累加1\n",
    "    componentIndex = 1\n",
    "    while fill:\n",
    "        r, c = fill.pop()\n",
    "        # 去掉以下判断并在向fill中添加上下左右点时增加对界限的判断是因为\n",
    "        # 当(r,c)位于边界处，且此时fill为空时\n",
    "        # 由于continue的存在，会跳过寻找下一个起始点，直接结束循环，导致有连通分量被漏掉\n",
    "        # if c > width or r > height or r < 0 or c < 0:\n",
    "        #     continue\n",
    "        if mask[r][c] == 0:\n",
    "            #print(r,c,':',componentIndex)\n",
    "            mask[r][c] = componentIndex\n",
    "            filled.add((r, c))\n",
    "            leftUp = (r - 1, c - 1)\n",
    "            left = (r, c - 1)\n",
    "            leftDown = (r + 1, c - 1)\n",
    "            up = (r - 1, c)\n",
    "            down = (r + 1, c)\n",
    "            rightUp = (r - 1, c + 1)\n",
    "            right = (r, c + 1)\n",
    "            rightDown = (r + 1, c + 1)\n",
    "            if leftUp not in filled and isInside(leftUp, (0, height),(0, width)):\n",
    "                fill.add(leftUp)\n",
    "            if left not in filled and isInside(left, (0, height), (0, width)):\n",
    "                fill.add(left)\n",
    "            if leftDown not in filled and isInside(leftDown, (0, height),(0, width)):\n",
    "                fill.add(leftDown)\n",
    "            if up not in filled and isInside(up, (0, height), (0, width)):\n",
    "                fill.add(up)\n",
    "            if down not in filled and isInside(down, (0, height), (0, width)):\n",
    "                fill.add(down)\n",
    "            if rightUp not in filled and isInside(rightUp, (0, height),(0, width)):\n",
    "                fill.add(rightUp)\n",
    "            if right not in filled and isInside(right, (0, height), (0, width)):\n",
    "                fill.add(right)\n",
    "            if rightDown not in filled and isInside(rightDown, (0, height),(0, width)):\n",
    "                fill.add(rightDown)\n",
    "        # print(fill)\n",
    "        # 若fill中此时没有别的点了，标明上下左右邻近范围内的点都已被搜索完，则已经完成一个连通分量的搜索\n",
    "        # 需要进行下一个连通分量的搜索\n",
    "        if not fill:\n",
    "            nextPoint = getNextStartPoint(mask)\n",
    "            #print('next:',nextPoint)\n",
    "            if nextPoint:\n",
    "                fill.add(nextPoint)\n",
    "                componentIndex = componentIndex + 1\n",
    "    return mask, componentIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mask, componetIndex = getConnectedComponet(reSizedIndicator)\n",
    "\n",
    "def getLargestConnectedComponent(mask, componetIndex):\n",
    "    \"\"\"获取最大连通分量\"\"\"\n",
    "    largestComponent = np.zeros_like(mask)\n",
    "    componetNumlist = [\n",
    "        np.argwhere(mask == i).shape[0] for i in range(1, componetIndex)\n",
    "    ]\n",
    "    largestComponetIndex = np.argmax(componetNumlist) + 1\n",
    "    largestComponent[mask == largestComponetIndex] = 1\n",
    "    return largestComponent\n",
    "\n",
    "\n",
    "# largestComp = getLargestConnectedComponent(mask, componetIndex)\n",
    "# plt.imshow(largestComp, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### DDT算法\n",
    "总结以上步骤，DDT算法流程为\n",
    "- 利用loadImages获取N张图片，形状为(N,C,H,W)\n",
    "- 利用getActivation获取这N张图片的激活图，形状为(N,H,W,D)。其中第n张图片的激活图即是一个高度为h，宽度为w的D维向量，称为deep desciptor\n",
    "- 利用getMeanVector获取所有N张图片的所有descriptors的平均向量\n",
    "- 利用cov获取这些descriptors的均方差矩阵\n",
    "- 利用getPrinCompVector计算均方差矩阵的最大成分向量，并作为主投影方向\n",
    "- 对于每一张图片\n",
    "    - 利用getIndicatorMatrix获取某一张图对应的指示矩阵。指示矩阵中的点是将对应图片的对应像素点的D维deep descriptor向量减去平均向量，再投影到最大成分向量的方向上。\n",
    "    - 利用reSize将指示矩阵的大小调整到原图片的大小(512,512)，得到新的指示矩阵\n",
    "    - 利用getConnectedComponet和getLargestConnectedComponent获取新指示矩阵的最大连接分量\n",
    "    - 返回每一张图片的最大连接分量形成的遮罩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def DDT(imgs: np.ndarray, net: torch.nn.Module):\n",
    "    \"\"\"利用DDT算法，获取图片的最大连接分量\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs : np.ndarray\n",
    "        N张图片构成的数组，形状为NCHW\n",
    "    net : torch.nn.Module\n",
    "        使用的CNN网络\n",
    "    modelParaPath : str\n",
    "        模型参数的路径\n",
    "    \"\"\"\n",
    "    activation = getActivation(net, imgs)\n",
    "    prinCompVector = getPrinCompVector(activation)\n",
    "    # largestComps = []\n",
    "    largestComps = np.zeros((imgs.shape[0],imgs.shape[2],imgs.shape[3]))\n",
    "    for i in range(imgs.shape[0]):\n",
    "        print('Processing pic {}/{}'.format(i + 1, imgs.shape[0]))\n",
    "        indicatorMat = getIndicatorMatrix(activation, i, prinCompVector)\n",
    "        reSizedIndicator = reSize(indicatorMat)\n",
    "        mask, componetIndex = getConnectedComponet(reSizedIndicator)\n",
    "        largestComp = getLargestConnectedComponent(mask, componetIndex)\n",
    "        # largestComps.append(largestComp)\n",
    "        largestComps[i] = largestComp\n",
    "    # largestComps = np.array(largestComps)\n",
    "    return largestComps\n",
    "\n",
    "\n",
    "def drawLargestComp(imgs: np.ndarray, largestComps: np.ndarray):\n",
    "    \"\"\"将图片与最大连接分量进行绘制\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs : np.ndarray\n",
    "        N张图片构成的数组，形状为NCHW\n",
    "    largestComps : np.ndarray\n",
    "        N张图片的最大连接分量\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(3.6 * 2, 4 * imgs.shape[0]))\n",
    "    for i in range(imgs.shape[0]):\n",
    "        plt.subplot(imgs.shape[0], 2, 2 * i + 1)\n",
    "        plt.imshow(imgs[i, 0], cmap='gray')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.subplot(imgs.shape[0], 2, 2 * i + 2)\n",
    "        plt.imshow(largestComps[i], cmap='gray')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "net = model.model_defination.LeNet5()\n",
    "parameter_path = r'D:\\Programming\\codetest\\CMEclassfication\\log\\2022_04_13_20_00_25\\parameters.pkl'\n",
    "net.load_param(parameter_path)\n",
    "imgarray = loadImages(r'D:\\Programming\\CME_data\\CME\\Halo')\n",
    "largestComps = DDT(imgarray, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drawLargestComp(imgarray, largestComps)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d77f6f2fe1d4ea854db94f6ad28dbb32cebc2f619ff9e2d22ef698e937c82f2"
  },
  "kernelspec": {
   "display_name": "PyCharm (CMEclassfication)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
