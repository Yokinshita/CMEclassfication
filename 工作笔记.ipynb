{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import model.train_schedule\n",
    "import model.model_defination\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\Programming\\CME_data\\CME\\Halo\\20130830_034712_lasc2rdf_aia193rdf.png'\n",
    "img = Image.open(path).convert('L')\n",
    "img = np.array(img, dtype=np.float32)\n",
    "print('图片大小：',img.shape)\n",
    "print(img)\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 预处理步骤\n",
    "首先，0.5级的LASCO C2数据文件会处理为1级数据。所有的1024*1024分辨率大小的图片会被下采样至512*512。然后，会经过噪声滤波以压制部分尖锐噪声。文中使用3*3正则化正方滤波器.该滤波器是基本的线性滤波器，计算邻近像素的平均值，然后再生成差分图。\n",
    "##### 图像分类\n",
    "所有的(1024,1024)差分图会被下采样(112,112)大小，作为神经网络的输入。经过卷积层1，输出为(20,108,108)，经过池化层1，输出为(20,54,54)，经过卷积层2，输出为(50,50,50)，经过池化层2，输出为(50,25,25).然后经过两全连接层，得到最终的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ho(h, f, padding, stride):\n",
    "    return (h - f + 2 * padding) / stride + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原文中:input N*112*112\n",
    "print('原文中：')\n",
    "print(ho(112, 5, 0, 1)) # 卷积后N*108*108\n",
    "print(ho(108, 2, 0, 2)) # 池化后N*54*54\n",
    "print(ho(54, 5, 0, 1)) # 卷积后N*50*50\n",
    "print(ho(50, 2, 0, 2)) # 池化后N*25*25\n",
    "\n",
    "#我的工作中采用input为 N*224*224\n",
    "print('我的工作：')\n",
    "print(ho(224, 5, 0, 1))  # 卷积后N*220*220\n",
    "print(ho(220, 2, 0, 2))  # 池化后N*110*110\n",
    "print(ho(110, 5, 0, 1))  # 卷积后N*106*106\n",
    "print(ho(106, 2, 0, 2))  # 池化后N*53*53\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CME探测\n",
    "首先利用register_forward_hook函数得到卷积层输出的activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'D:\\Programming\\CME_data\\CME\\Halo\\20130830_031208_lasc2rdf_aia193rdf.png'\n",
    "net = model.model_defination.Net()\n",
    "parameter_path = r'D:\\Programming\\codetest\\CMEclassfication\\train_info\\2022_03_27_16_54_16\\parameters.pkl'\n",
    "net.load_state_dict(torch.load(parameter_path))\n",
    "net.eval()\n",
    "activation = []\n",
    "\n",
    "\n",
    "def forward_hook(module, data_input, data_output):\n",
    "    activation.append(data_output)\n",
    "\n",
    "\n",
    "net.conv5.register_forward_hook(forward_hook)\n",
    "\n",
    "\n",
    "def infer(net, path):\n",
    "    img = Image.open(path).convert('L')\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = torch.from_numpy(img)\n",
    "    y = torch.argmax(net(img))\n",
    "    return y\n",
    "\n",
    "\n",
    "print(infer(net, img_path))\n",
    "print(activation[0])\n",
    "print(activation[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### CME Co-localiaztion\n",
    "从卷积层的输出特征图中提取信息。利用DDT手段进行图像共定位(Co-locolization)。共定位就是在一系列的图像中找到相关物体的位置。对于一张H*W大小的图片，其activation(卷积层的输出)就是一个形状为h*w*d的三维张量。该张量可被认为有h*w个cell，每个cell包含一个d维的DD(deep desciptor)向量。  \n",
    "首先，有N张图片构成的序列，这N个图片包含着同一类别的目标。这N张图片生成N个activation，每一个activation都是k*w*d维的张量。计算这N个activation的平均张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得所有descriptor的平均向量\n",
    "def getMeanVector(x):  #x为N*h*w*d维的np.array\n",
    "    return np.mean(x, axis=(0, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12)\n",
    "a = np.reshape(a, (2, 2, 3))\n",
    "print(np.mean(a, axis=(0, 1)))\n",
    "print(a[1][1].shape)\n",
    "print('直接相乘的结果：')\n",
    "print(np.matmul(a[1][1], a[1][1]))\n",
    "print('升维后：')\n",
    "b = np.expand_dims(a[1][1], 1)\n",
    "print(b.shape)\n",
    "np.matmul(b, b.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后获得协方差矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(x: np.ndarray):  #x为N*h*w*d维的np.array\n",
    "    k = x.shape[0] * x.shape[1] * x.shape[2]\n",
    "    xMeanVector = getMeanVector(x)\n",
    "    convMat = np.zeros(x.shape[3])\n",
    "    for n in range(x.shape[0]):\n",
    "        for i in range(x.shape[1]):\n",
    "            for j in range(x.shape[2]):\n",
    "                deviaVector = x[n][i][j] - xMeanVector\n",
    "                assert deviaVector.shape == (x.shape[3], )\n",
    "                # 对x中取出的descripter向量进行升维\n",
    "                # 因为直接取出的descripter向量是一维的，直接相乘会出现问题，需转化为列向量\n",
    "                deviaVector = np.expand_dims(deviaVector, axis=1)\n",
    "                tempMat = np.matmul(deviaVector, deviaVector.T)\n",
    "                convMat = convMat + tempMat\n",
    "    return convMat / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d77f6f2fe1d4ea854db94f6ad28dbb32cebc2f619ff9e2d22ef698e937c82f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
